{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.amp import GradScaler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import logging\n",
    "from utils.train import train\n",
    "from utils.checkpoint import (\n",
    "    load_checkpoint,\n",
    "    create_checkpoint,\n",
    "    save_weights,\n",
    ")\n",
    "\n",
    "from utils import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch._logging.set_logs(all=logging.ERROR)\n",
    "torch.multiprocessing.set_start_method(\"spawn\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"resnet50\"\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "SEED = 11\n",
    "LR = 1e-2\n",
    "WEIGHT_DECAY = 1e-4\n",
    "LOAD = True\n",
    "CHECKPOINT_NAME = \"checkpoint.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomCrop((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = ImageFolder(\n",
    "    \"data/images/\",\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "class_weight = compute_class_weight(\n",
    "    \"balanced\",\n",
    "    classes=np.arange(10),\n",
    "    y=dataset.targets,\n",
    ")\n",
    "\n",
    "print(dataset.class_to_idx)\n",
    "print(class_weight)\n",
    "class_weight = torch.tensor(class_weight, dtype=torch.float32)\n",
    "\n",
    "train_indices, test_indices = train_test_split(\n",
    "    range(len(dataset.targets)),\n",
    "    test_size=0.2,\n",
    "    stratify=dataset.targets,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = get_model(MODEL).to(device)\n",
    "model.compile(dynamic=False, mode=\"max-autotune\")\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weight.to(device))\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer,\n",
    "    milestones=[30, 60],\n",
    "    gamma=0.1,\n",
    ")\n",
    "scaler = GradScaler(device)\n",
    "writer = SummaryWriter(log_dir=f\"logs/{MODEL}\")\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD:\n",
    "    try:\n",
    "        epoch += load_checkpoint(\n",
    "            dir=f\"data/checkpoints/{MODEL}\",\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            scaler=scaler,\n",
    "            scheduler=scheduler,\n",
    "            name=CHECKPOINT_NAME,\n",
    "        )\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scaler=scaler,\n",
    "    scheduler=scheduler,\n",
    "    writer=writer,\n",
    "    epochs=EPOCHS,\n",
    "    start_epoch=epoch,\n",
    "    checkpoint_dir=f\"data/checkpoints/{MODEL}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_checkpoint(\n",
    "    dir=f\"data/checkpoints/{MODEL}\",\n",
    "    model=model,\n",
    "    epoch=epoch,\n",
    "    optimizer=optimizer,\n",
    "    scaler=scaler,\n",
    "    scheduler=scheduler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_weights(model, MODEL)\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
